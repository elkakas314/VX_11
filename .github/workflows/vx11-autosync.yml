name: VX11 Autosync (Safe Auto-Merge)

on:
    workflow_dispatch:
        inputs:
            reason:
                description: "Reason for autosync trigger"
                required: false
                default: "manual_trigger"
            run_dbmap:
                description: "If true, run DBMAP (rotate backups + generate maps) as a read-only job (no git push)."
                required: false
                default: "false"
    push:
        branches:
            - main
        paths:
            - "docs/**"
            - ".github/copilot-instructions.md"
            - "config/*.py"
            - ".gitignore"

jobs:
    validate:
        name: Validate Before Autosync
        runs-on: ubuntu-latest
        outputs:
            safe: ${{ steps.check.outputs.safe }}
        steps:
            - uses: actions/checkout@v4
              with:
                  fetch-depth: 0

            - name: Set up Python 3.11
              uses: actions/setup-python@v4
              with:
                  python-version: "3.11"
                  cache: "pip"

            - name: Python Syntax Check
              id: py_syntax
              run: |
                  python -m compileall tentaculo_link operator_backend config 2>&1 | tee /tmp/syntax.log
                  if grep -q "SyntaxError" /tmp/syntax.log; then
                    echo "❌ Python syntax errors detected"
                    exit 1
                  fi
                  echo "✓ Python syntax OK"

            - name: Docker Compose Validation
              id: docker_check
              continue-on-error: true
              run: |
                  which docker-compose || which docker || { echo "Docker not available (OK for CI)"; exit 0; }
                  docker-compose config > /dev/null 2>&1 && echo "✓ Docker config OK" || echo "⚠️ Docker config check skipped"

            - name: Import Check (No Cross-Module)
              id: imports_check
              run: |
                  VIOLATIONS=$(grep -r "^from tentaculo_link import\|^from madre import\|^from switch import\|^from hermes import\|^from hormiguero import\|^from manifestator import\|^from mcp import\|^from shubniggurath import" \
                    --include="*.py" \
                    tentaculo_link/ madre/ switch/ hermes/ hormiguero/ manifestator/ mcp/ shubniggurath/ 2>/dev/null | grep -v "test\|__pycache__" || echo "")
                  if [ -n "$VIOLATIONS" ]; then
                    echo "❌ Cross-module imports detected:"
                    echo "$VIOLATIONS"
                    exit 1
                  fi
                  echo "✓ No cross-module imports"

            - name: Secret Scan
              id: secrets_check
              run: |
                  SECRETS=$(grep -r "password=\|token=\|api_key=\|secret=" --include="*.py" \
                    tentaculo_link/ operator_backend/ config/ 2>/dev/null | \
                    grep -v "\.env\|tokens.env\|settings.py\|deepseek.py" || echo "")
                  if [ -n "$SECRETS" ]; then
                    echo "❌ Possible secrets detected:"
                    echo "$SECRETS"
                    exit 1
                  fi
                  echo "✓ No hardcoded secrets"

            - name: .gitignore Compliance
              id: gitignore_check
              run: |
                  TRACKED=$(git ls-files | grep -E "node_modules/|dist/|\.venv/|__pycache__|\.pytest_cache" || echo "")
                  if [ -n "$TRACKED" ]; then
                    echo "❌ Ignored files are tracked:"
                    echo "$TRACKED"
                    exit 1
                  fi
                  echo "✓ .gitignore compliant"

            - name: Git Status Check
              id: git_check
              run: |
                  UNCOMMITTED=$(git status --porcelain | grep -v "^\??" || echo "")
                  if [ -n "$UNCOMMITTED" ]; then
                    echo "⚠️ Uncommitted changes:"
                    echo "$UNCOMMITTED"
                    echo "Not blocking (may be forensics or logs)"
                  fi
                  DIVERGE=$(git rev-list --left-only --count main...origin/main 2>/dev/null || echo "0")
                  if [ "$DIVERGE" -gt 50 ]; then
                    echo "❌ Main is 50+ commits behind origin"
                    exit 1
                  fi
                  echo "✓ Git status OK"

            - name: VX11 Autosync Runner
              id: vx11_autosync
              continue-on-error: true
              run: |
                  set -e
                  python3 -m pip install PyYAML pydantic_settings > /dev/null 2>&1
                  if [ -f scripts/vx11_workflow_runner.py ]; then
                    python scripts/vx11_workflow_runner.py autosync
                  else
                    echo "⚠️ vx11_workflow_runner.py not found"
                  fi

            - name: Overall Safety Check
              id: check
              run: |
                  if [ "${{ steps.py_syntax.outcome }}" != "success" ]; then
                    echo "safe=false" >> $GITHUB_OUTPUT
                    echo "❌ Python syntax failed"
                    exit 1
                  fi
                  if [ "${{ steps.imports_check.outcome }}" != "success" ]; then
                    echo "safe=false" >> $GITHUB_OUTPUT
                    exit 1
                  fi
                  if [ "${{ steps.secrets_check.outcome }}" != "success" ]; then
                    echo "safe=false" >> $GITHUB_OUTPUT
                    exit 1
                  fi
                  if [ "${{ steps.gitignore_check.outcome }}" != "success" ]; then
                    echo "safe=false" >> $GITHUB_OUTPUT
                    exit 1
                  fi
                  echo "safe=true" >> $GITHUB_OUTPUT
                  echo "✅ All validation checks passed"

    autosync:
        name: Autosync to Main
        runs-on: ubuntu-latest
        needs: validate
        if: needs.validate.outputs.safe == 'true'
        steps:
            - uses: actions/checkout@v4
              with:
                  ref: ${{ github.head_ref }}
                  fetch-depth: 0

            - name: Configure Git
              run: |
                  git config user.name "VX11-Operator"
                  git config user.email "operator@vx11.local"

            - name: Verify Main
              run: |
                  git fetch origin main
                  BEHIND=$(git rev-list --count main..origin/main 2>/dev/null || echo "0")
                  if [ "$BEHIND" -gt 0 ]; then
                    echo "⚠️ Branch is $BEHIND commits behind main"
                  fi

            - name: Create Summary
              run: |
                  cat > /tmp/autosync_summary.txt <<EOF
                  ✅ Autosync Validation Passed
                  - Python syntax: OK
                  - Imports: No violations
                  - Secrets: None detected
                  - .gitignore: Compliant
                  - Git state: Clean

                  Changes to merge:
                  $(git diff --stat main...HEAD || echo "No changes")

                  Triggered: ${{ github.event.inputs.reason || 'automatic' }}
                  EOF
                  cat /tmp/autosync_summary.txt

            - name: Log Event
              run: |
                  mkdir -p docs/audit
                  echo "$(date -u +%Y-%m-%dT%H:%M:%SZ) [AUTOSYNC] Validation passed, merged to main" >> docs/audit/AGENT_LOG.md
                  git add docs/audit/AGENT_LOG.md || true

            - name: Push Summary
              if: github.event_name == 'workflow_dispatch'
              run: |
                  echo "Autosync complete. Review main branch for merged changes."

  dbmap_run:
    name: DBMAP Run (manual)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.run_dbmap == 'true' }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Ensure dirs
        run: |
          mkdir -p data/backups docs/audit

      - name: Rotate backups (cp only)
        run: |
          set -e
          if [ -f data/backups/vx11.db.canonical_prev1.db ]; then
            cp -f data/backups/vx11.db.canonical_prev1.db data/backups/vx11.db.canonical_prev2.db || true
          fi
          if [ -f data/backups/vx11.db.canonical_latest.db ]; then
            cp -f data/backups/vx11.db.canonical_latest.db data/backups/vx11.db.canonical_prev1.db || true
          fi
          if [ -f data/runtime/vx11.db ]; then
            cp -f data/runtime/vx11.db data/backups/vx11.db.canonical_latest.db
          else
            echo "DB missing: data/runtime/vx11.db"; exit 2
          fi

      - name: Integrity check and write META
        run: |
          python3 - <<'PY'
import sqlite3, os, time
db='data/runtime/vx11.db'
meta='docs/audit/DB_MAP_v7_META.txt'
if not os.path.exists(db):
    print('DB missing:',db)
    raise SystemExit(2)
con=sqlite3.connect(db)
cur=con.cursor()
try:
    cur.execute('PRAGMA integrity_check;')
    res=cur.fetchall()
    integrity=';'.join([r[0] for r in res])
except Exception as e:
    integrity=str(e)
finally:
    con.close()
TS=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
rt=os.path.getsize(db)
latest=os.path.getsize('data/backups/vx11.db.canonical_latest.db') if os.path.exists('data/backups/vx11.db.canonical_latest.db') else 0
with open(meta,'w') as f:
    f.write(f'timestamp_utc: {TS}\n')
    f.write(f'runtime_db_size_bytes: {rt}\n')
    f.write(f'canonical_latest_size_bytes: {latest}\n')
    f.write(f'integrity_check: {integrity}\n')
print('WROTE',meta)
PY

      - name: Generate DB map/schema
        run: |
          if [ -f scripts/generate_db_map_from_db.py ]; then
            python3 scripts/generate_db_map_from_db.py || true
          elif [ -f scripts/vx11_scan_and_map.py ]; then
            python3 scripts/vx11_scan_and_map.py || true
          else
            echo "No generator script found"; exit 4
          fi

      - name: Ensure canonical outputs
        run: |
          if [ -f docs/audit/DB_SCHEMA_v7_FINAL.json ]; then echo 'OK'; else if [ -f docs/audit/DB_SCHEMA.json ]; then cp -f docs/audit/DB_SCHEMA.json docs/audit/DB_SCHEMA_v7_FINAL.json; fi; fi
          if [ -f docs/audit/DB_MAP_v7_FINAL.md ]; then echo 'OK'; else if [ -f docs/audit/DB_MAP_FINAL.md ]; then cp -f docs/audit/DB_MAP_FINAL.md docs/audit/DB_MAP_v7_FINAL.md; fi; fi

      - name: Size checks
        run: |
          for f in docs/audit/DB_SCHEMA_v7_FINAL.json docs/audit/DB_MAP_v7_FINAL.md docs/audit/DB_MAP_v7_META.txt; do
            if [ -f "$f" ]; then sz=$(stat -c%s "$f"); echo "$f size=$sz"; if [ "$sz" -gt $((500*1024*1024)) ]; then echo "TOO_LARGE"; exit 5; fi; else echo "MISSING $f"; exit 6; fi
          done

      - name: Run tests (smoke)
        run: |
          python3 -m pip install -r requirements.txt pytest || true
          pytest -k "hermes or switch" -q || true

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: dbmap-artifacts
          path: |
            docs/audit/DB_SCHEMA_v7_FINAL.json
            docs/audit/DB_MAP_v7_FINAL.md
            docs/audit/DB_MAP_v7_META.txt
          retention-days: 7

    report:
        name: Report Autosync Status
        runs-on: ubuntu-latest
        needs: [validate, autosync]
        if: always()
        steps:
            - name: Status Report
              run: |
                  if [ "${{ needs.validate.outputs.safe }}" == "true" ]; then
                    echo "✅ Autosync: VALIDATED (all checks passed)"
                  else
                    echo "❌ Autosync: BLOCKED (validation failed)"
                    exit 1
                  fi
